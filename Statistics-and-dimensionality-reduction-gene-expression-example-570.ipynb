{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77157935",
   "metadata": {},
   "source": [
    "*This jupyter notebook is part of Arizona State University's course CAS 570 (Introduction to Complex Systems Science) and was written by Bryan Daniels.  It was last updated November 6, 2023.*\n",
    "\n",
    "*This notebook uses data gathered by Ying Wang and Robert E. Page, Jr. at Arizona State University.  The data can be accessed [here](https://figshare.com/articles/dataset/Data_Archive_for_Identifying_a_developmental_transition_in_honey_bees_using_gene_expression_data_/22696312).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f777706",
   "metadata": {},
   "source": [
    "# Statistical analysis of honey bee gene expression data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d58bf",
   "metadata": {},
   "source": [
    "In this notebook, we will practice using Principal Components Analysis to extract useful insights from a large-dimensional set of gene expression data.  We will see how a scientific question can be more easily approached when we visualize the data in a lower-dimensional space.\n",
    "\n",
    "We will attempt to find a generative model that can output data that matches the statistics we measure in the data. In this case, the inferred model will take the form of a probability distribution of gene expression values, predicting which combinations of gene expression are more or less likely.  A typical challenge when inferring such models is selecting the best form of model:  Will a simple model suffice, or do we need to include more detail?  Here, we will use the \"Bayesian information criterion\" as a measure to decide which model is best.\n",
    "\n",
    "This is part of a research project that I worked on together with Ying Wang, Rob Page, and Gro Amdam here at ASU, who are experts in honey bee physiology, behavior, and genetics.  Combining my expertise in physics and complex systems data analysis, this project is also a good example of the results of interdisciplinary collaboration.  Our writeup on the project can be found [here](https://doi.org/10.1371/journal.pcbi.1010704)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af585cd",
   "metadata": {},
   "source": [
    "## Get set up and load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c60345",
   "metadata": {},
   "source": [
    "Let's load some useful basic packages and functions first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from gene_expression_example.landau import LandauDistributionPDF\n",
    "plt.rcParams.update({'font.size': 18}) # increases font size on plots\n",
    "#from helpers.prettyPlotting import scatter1D # custom 1D scatter plot\n",
    "from pathlib import Path # to handle file paths across all operating systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cad462",
   "metadata": {},
   "source": [
    "We will use the scikit learn function `sklearn.decomposition.PCA` to perform PCA.  The documentation is available [here](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a8c23c",
   "metadata": {},
   "source": [
    "Now load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf2a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = Path('nanostring data with VG protein data.xlsx')\n",
    "columnsToDrop = ['Gene','Unnamed: 2','Unnamed: 3','Sample ID','VG protein ']\n",
    "expressionData = np.log(pd.read_excel(dataPath).drop(columns=columnsToDrop).set_index('Age'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a9be03",
   "metadata": {},
   "source": [
    "## What do these data represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56917cef",
   "metadata": {},
   "source": [
    "These measurements were taken in honey bees at a precise time during their development (15 days old) when some bees are starting to leave the nest to forage for food.  Interestingly, some bees become foragers at a much younger age, while others stay in the nest much longer to take care of younger bees.  This transition is relatively sudden, with few bees switching back to in-nest activities once they start foraging.  There seem to be two separate \"types\" of bees related to which tasks they perform.  This is similar to how different cell types perform different tasks in your body.\n",
    "\n",
    "Our question: As in cells in human development, are different bee types (those that perform distinct functions) related to which genes are expressed?\n",
    "\n",
    "My collaborators chose genes to measure that were suspected to be related to the behavioral transition to foraging.  These data represent how strongly these genes are expressed in individual honey bees.  (Specifically, these are [measurements of the amount of RNA](https://en.wikipedia.org/wiki/RNA-Seq) present for each of the genes of interest.  We have taken the logarithm of the raw data to more easily capture wide variations in expression.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b4ca3c",
   "metadata": {},
   "source": [
    "Let's first look at the form of the data we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = 15 # days\n",
    "expressionData.loc[age]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e1e2c6",
   "metadata": {},
   "source": [
    "This is a `pandas` dataframe in which the columns represent the genes (90 of them) and the rows represent 16 individual bees whose gene expression was measured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb571c",
   "metadata": {},
   "source": [
    "The default when printing a dataframe to the screen is to hide as many rows and columns as necessary to fit on a screen at once without a lot of scrolling.  To see the names of all the genes in the data, we can look at the `columns` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c847ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "expressionData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a47a433",
   "metadata": {},
   "source": [
    "# 1) Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00041cfa",
   "metadata": {},
   "source": [
    "## The distribution of individual genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e10bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = 'vg'\n",
    "\n",
    "# plot histogram\n",
    "expressionData[gene].plot.hist(bins=20) #,density=True)\n",
    "plt.xlabel('Expression of gene {}'.format(gene))\n",
    "plt.ylabel('Number of bees');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5cdc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a normal distribution\n",
    "paramsNormal = stats.norm.fit(expressionData[gene])\n",
    "print(\"Best-fit parameters: mean = {:1.5}, std. dev. = {:1.5}.\".format(*paramsNormal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97144f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram with overlaid best fit normal distribution\n",
    "expressionData[gene].plot.hist(bins=20,density=True)\n",
    "xs = np.linspace(8,15,100)\n",
    "plt.plot(xs,[stats.norm.pdf(x,*paramsNormal) for x in xs],lw=5)\n",
    "plt.xlabel('Expression of gene {}'.format(gene))\n",
    "plt.ylabel('Probability density')\n",
    "plt.title('Normal distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf03b8e",
   "metadata": {},
   "source": [
    "## Try visualizing in 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af407f91",
   "metadata": {},
   "source": [
    "Due to the large dimensionality of the dataset, it can be difficult to decide which aspects to focus on for thinking about our question about bee types.  Which genes are important?\n",
    "\n",
    "One way to start is to visualize the data in lower dimensions by focusing on one or a few genes of interest at a time.  An easy way to do this using `pandas` is to use the `plot.scatter` function, which takes the names of two columns and constructs a scatter plot.  For example, we can visualize the expression of the genes *vg* and *ILP-2* in our 16 bees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5a8dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "expressionData.plot.scatter('vg','ILP-2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "expressionData.plot.scatter('AKHR','proPO');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "expressionData.plot.scatter('ilp1','LOC102655054');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b8ad71",
   "metadata": {},
   "source": [
    "As I initially played around with these data, I happened to find that the pair of genes *vg* and *P110* made for an intriguing scatter plot, particularly when restricting to the oldest bees (age 15 days):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "expressionData.plot.scatter('vg','P110');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "expressionData.loc[15].plot.scatter('vg','P110');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977b74f",
   "metadata": {},
   "source": [
    "# 2) Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = expressionData.corr()\n",
    "# remove correlations with self\n",
    "for gene in correlations.index:\n",
    "    correlations.loc[(gene,gene)] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the pair of genes with largest correlation\n",
    "gene1 = correlations.max().idxmax()\n",
    "gene2 = correlations.idxmax()[gene1]\n",
    "print(\"The pair of genes with largest linear correlation is {} and {}.\".format(gene1,gene2))\n",
    "r,p = stats.pearsonr(expressionData[gene1],expressionData[gene2])\n",
    "print(\"These have a correlation coefficient of {:1.5}, with p-value {:1.5}.\".format(r,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expressionData.plot.scatter('AGO1','Ftz-f1');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa69f9d",
   "metadata": {},
   "source": [
    "# 3) Reduce dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde4ef58",
   "metadata": {},
   "source": [
    "Instead of searching through many possible genes related to this transition, can we use dimensionality reduction to find one or a few dimensions that are particularly interesting?\n",
    "\n",
    "Recall that Principal Components Analysis (PCA) is one way of picking out such dimensions: PCA chooses the dimensions with largest variance.  This could be useful for our question about bee types because, if gene expression varies with bee type, then we expect larger variance (and correlated variance) among the genes that define the distinct bee types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6622839e",
   "metadata": {},
   "source": [
    "The following code runs PCA on our expression data from the oldest bees (day 15), keeping only the 10 components with largest variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f711f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = 15 # days\n",
    "pca_results = PCA(n_components=10).fit(expressionData.loc[age])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83a6e9",
   "metadata": {},
   "source": [
    "The results are stored as attributes of the `pca_results` object, which we explore below.  (If you are curious about what all is in there, recall how tab completion works in jupyter notebooks: you can type `pca_results.` followed by the tab key to see a list of the object's subparts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ddb10e",
   "metadata": {},
   "source": [
    "## How low-dimensional are the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d5e36",
   "metadata": {},
   "source": [
    "As a first step for thinking about what PCA is doing, let's ask how much variance there is in the data along each of these first 10 components.  Specifically, we'll ask what proportion of the total variance lies along each principal component.  This is stored as `explained_variance_ratio_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e22c5d",
   "metadata": {},
   "source": [
    "By construction, the first components have the largest variance (or \"explain\" the most variance, in the common lingo).\n",
    "\n",
    "A common way of visualizing this is to plot the total variance included as a function of the number of principal components kept.  The following code computes this \"cumulative sum\" and plots it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_explained_cumulative = pca_results.explained_variance_ratio_.cumsum()\n",
    "plt.plot(np.arange(len(var_explained_cumulative))+1,var_explained_cumulative,'o:')\n",
    "plt.xlabel('Number of principal components')\n",
    "plt.ylabel('Proportion of\\nvariance included')\n",
    "plt.axis(xmin=1,ymax=1,ymin=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8a219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_explained_cumulative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a661fa2b",
   "metadata": {},
   "source": [
    "## Interpreting the first principal component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fb2dea",
   "metadata": {},
   "source": [
    "For our question about bee types, it makes sense to focus on the first principal component (the one with largest variance): If the dissimilarity in bee behavior is connected strongly to gene expression, then we expect these large differences in behavior to correspond to large differences in gene expression.  We are looking for large variance!\n",
    "\n",
    "The first principal component is stored in `pca_results` as `components_[0]` (I include the names of the genes here by creating a `pandas` series indexed by the names in `expressionData.columns`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f15a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "component1 = pd.Series(pca_results.components_[0],\n",
    "                       index = expressionData.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337f61f5",
   "metadata": {},
   "source": [
    "Let's see what the first component looks like.  Recall that a principal component is defined in terms of weights given to each of the original dimensions (each of the original genes, in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "component1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab73da",
   "metadata": {},
   "source": [
    "So the principal component is a list of length 90, with a weight for each gene (either positive or negative).\n",
    "\n",
    "I typically find it useful to visualize things when possible.  Here's one way to visualize the principal component (I split into two plots for easier leigibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea65b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,2))  # set up a large plot area\n",
    "component1[:45].plot.bar(); # plot the weights of the first 45 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,2))  # set up a large plot area\n",
    "component1[45:].plot.bar(); # plot the weights of all genes past the first 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda85f63",
   "metadata": {},
   "source": [
    "How to interpret these results?  Most genes don't contribute much to the principal component (they have small weights), and a few contribute a lot.  One way to find the genes that contribute most is to sort by the absolute value of their weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(component1).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce44acd",
   "metadata": {},
   "source": [
    "So *hex 110* has the largest contribution, followed by *Hex70a*, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785e180",
   "metadata": {},
   "source": [
    "## Reducing data to a single dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1e578",
   "metadata": {},
   "source": [
    "Of course, the point of dimensionality reduction is that we can look at the data using these reduced coordinates.  In the extreme case, instead of the full dimensionality of the dataset, we can characterize each sample (each bee) by a *single* number.  This number is the \"linear projection\" of the full dimensional data onto the principal component—that is, we weight the gene expression of each bee by multiplying by the weights of the first principal component, then add them up to get a single value.\n",
    "\n",
    "This projection, also called a \"dot product\", is accomplished by `np.dot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cde156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_along_component1 = np.dot(expressionData.loc[age],component1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd5c7f",
   "metadata": {},
   "source": [
    "Projected along the first principal component, our dataset is reduced to 16 single numbers, one for each bee:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228afe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_along_component1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9169bc",
   "metadata": {},
   "source": [
    "We might make a histogram to visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data_along_component1,bins=10)\n",
    "plt.xlabel('Distance along first component')\n",
    "plt.ylabel('Number of bees')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f694c",
   "metadata": {},
   "source": [
    "# Separate bees into potential groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3cc22c",
   "metadata": {},
   "source": [
    "We might separate bees into groups by setting a threshold along the first principal component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f1cf5",
   "metadata": {},
   "source": [
    "Insert your threshold into the following code, which then splits the bees into two groups and assigns them colors based on which group they are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -8 \n",
    "beesA = np.where(data_along_component1 > threshold)[0]\n",
    "beesB = np.where(data_along_component1 < threshold)[0]\n",
    "\n",
    "# make list of colors based on the group\n",
    "colors = []\n",
    "for i in range(16):\n",
    "    if i in beesA: \n",
    "        colors.append('crimson')\n",
    "    else: \n",
    "        colors.append('cornflowerblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab32122",
   "metadata": {},
   "source": [
    "Here's an example using the colors in a scatter plot (where red dots correspond to bees in group A, and blue to group B):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcec39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# largest contributors to component 1\n",
    "expressionData.loc[age].plot.scatter('hex 110','Hex70a',\n",
    "                            c=colors,s=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42985630",
   "metadata": {},
   "outputs": [],
   "source": [
    "expressionData.loc[age].plot.scatter('vg','P110',\n",
    "                            c=colors,s=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4173b5",
   "metadata": {},
   "source": [
    "# 4) Simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981b00ee",
   "metadata": {},
   "source": [
    "Now we will aim for a generative model.  A generative model acts as a hypothesis that produces data similar to what we observed in the actual system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "expressionDataDay1 = expressionData.loc[1]\n",
    "expressionDataDay15 = expressionData.loc[15]\n",
    "\n",
    "pcaProjectionsDay1 = PCA(n_components=1).fit_transform(expressionDataDay1)\n",
    "pcaProjectionsDay15 = PCA(n_components=1).fit_transform(expressionDataDay15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c9603f",
   "metadata": {},
   "source": [
    "To create a generative model, can we find a probability distribution that gives a reasonable approximation of the data along the principal component?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcef243",
   "metadata": {},
   "source": [
    "First try a normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f087b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsNormalDay15 = stats.norm.fit(pcaProjectionsDay15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df54313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the best-fit normal distribution\n",
    "plt.hist(pcaProjectionsDay15,bins=10,density=True)\n",
    "xs = np.linspace(-15,15,100)\n",
    "plt.plot(xs,[stats.norm.pdf(x,*paramsNormalDay15) for x in xs],lw=5)\n",
    "plt.xlabel('Distance along first component')\n",
    "plt.ylabel('Probability density')\n",
    "plt.title('Day 15, Unimodal distribution fit');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72833b0d",
   "metadata": {},
   "source": [
    "The function `nnlf` returns the negative log-likelihood of the data given the model, so `-nnlf` is the standard log-likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalLogLDay15 = -stats.norm.nnlf(paramsNormalDay15,pcaProjectionsDay15)[0]\n",
    "print(\"The log-likelihood for the Normal distribution model on Day 15 data is {}.\".format(normalLogLDay15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb59c9",
   "metadata": {},
   "source": [
    "In a particular mathematical sense that I won't describe in detail here, the simplest distribution with *two* peaks (bimodal) is what I will call the \"Landau\" distribution.  This distribution corresponds to a very simplistic model of phase transitions in statistical physics. Here's the form of the distribution in case you are interested:\n",
    "\n",
    "$$\n",
    "p(x) = \\frac{1}{Z} \\exp \\left( -\\frac{c}{2} (x-\\mu)^2 - \\frac{d}{4} (x-\\mu)^4 \\right),\n",
    "$$\n",
    "\n",
    "where $Z$ is a normalization constant.  \n",
    "\n",
    "The Landau distribution has three parameters ($\\mu$, $c$, and $d$) compared to the Gaussian model's two parameters ($\\mu$ and $\\sigma$).  Note that the Gaussian is a special case of the Landau distribution: setting $d=0$ gives the usual form of a Gaussian.  So this model can have a single peak or two peaks depending on the values of the parameters.\n",
    "\n",
    "The Landau distribution is not standard enough to be implemented in the packages we use here, so I've done the fitting of parameters for you.  We load these parameters here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d73ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "landauFitParameters = pd.read_csv(Path('gene_expression_example/landau_fit_parameters.csv'),index_col='age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the best-fit Landau distribution\n",
    "age = 15 # age of bees in days\n",
    "params = landauFitParameters.loc[age]\n",
    "plt.hist(pcaProjectionsDay15,bins=10,density=True)\n",
    "xs = np.linspace(-15,15,100)\n",
    "plt.plot(xs,LandauDistributionPDF(xs,params['mu'],params['c'],params['d']),lw=5)\n",
    "plt.xlabel('Distance along first component')\n",
    "plt.ylabel('Probability density')\n",
    "plt.title('Day 15, Bimodal distribution fit');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec215dc",
   "metadata": {},
   "source": [
    "This looks like a much better fit!  Still, it's not exactly right—but then again, we only have 16 datapoints, so we don't expect the fit to be exactly right.  How do we decide if it's better enough compared to the unimodal distribution?  This is a job for statistical model selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2978d",
   "metadata": {},
   "source": [
    "First, let's look at the log-likelihood of the data given the Landau model.  I also have this pre-saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "landauLogLDay15 = landauFitParameters.loc[15]['log-likelihood']\n",
    "print(\"The log-likelihood for the Landau model on Day 15 data is {}.\".format(landauLogLDay15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f13e8e4",
   "metadata": {},
   "source": [
    "This is a better fit according to the log-likelihood.\n",
    "\n",
    "But notice that the unimodal distribution is a special case of the bimodal distribution.\n",
    "That is, after we have added new parameters, we could still produce the same unimodal behavior as before.\n",
    "\n",
    "In this case, it is not possible to be forced to have a worse fit with the more complicated model — you could always just use the setting of the new parameter that gives the same answer as the simpler model.  So the new, larger model will *always* fit better, no matter the data.  (Well, I suppose it could also fit the same—it's just not possible for the fit to get worse.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443dab39",
   "metadata": {},
   "source": [
    "This logic means that our better fit with the more complicated model is not so impressive.  In other language we have encountered in this class, it's possible that the new, more complicated model is simply *overfitting*: fitting noise in the data.\n",
    "\n",
    "To determine if the extra parameter is \"worth the trouble\", we will compute the Bayesian information criterion (BIC).  The BIC includes a penalty on more complicated models, essentially setting a bar for *how much* better a model with extra parameters must fit the data to be statistically favored.\n",
    "\n",
    "The BIC is defined as\n",
    "$$\n",
    "\\textrm{BIC} = L - \\frac{1}{2} N_{params} \\log(N_{datapoints}),\n",
    "$$\n",
    "where $L$ is the log-likelihood, $N_{params}$ is the number of free parameters in the model, and $N_{datapoints}$ is the number of datapoints to which the model was fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c235ca2",
   "metadata": {},
   "source": [
    "The following code computes BIC for the Normal and Landau models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7451b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute bic for normal distribution model\n",
    "numParamsNormal = 2\n",
    "numDatapoints = 16\n",
    "normalBICDay15 = normalLogLDay15 - numParamsNormal/2 * np.log(numDatapoints)\n",
    "\n",
    "# compute bic for landau distribution model\n",
    "numParamsLandau = 3\n",
    "numDatapoints = 16\n",
    "landauBICDay15 = landauLogLDay15 - numParamsLandau/2 * np.log(numDatapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e46c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Day 15:\")\n",
    "print(\"    The Gaussian model has BIC = {} and the Landau model has BIC = {}.\".format(\n",
    "    normalBICDay15,landauBICDay15))\n",
    "print(\"    The Landau model has larger BIC by a difference of {}.\".format(\n",
    "    landauBICDay15-normalBICDay15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f38700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the best-fit Landau distribution\n",
    "age = 1 # age of bees in days\n",
    "params = landauFitParameters.loc[age]\n",
    "plt.hist(pcaProjectionsDay1,bins=10,density=True)\n",
    "xs = np.linspace(-15,15,100)\n",
    "plt.plot(xs,LandauDistributionPDF(xs,params['mu'],params['c'],params['d']),lw=5)\n",
    "plt.xlabel('Distance along first component')\n",
    "plt.ylabel('Probability density')\n",
    "plt.title('Day 1, Bimodal distribution fit');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9c0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
